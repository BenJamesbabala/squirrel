(A) FEATURE EXTRACTION

Go to the directory 00_feature_extraction.

(1) Run 00_convert.sh to convert the output of the dense trajectory algorithm
(available at http://lear.inrialpes.fr/people/wang/improved_trajectories) to
squirrel caches for each of the five descriptors (traj, hog, hof, mbhx, mbhy).
The script converts all .gz files in bow-nn-bmvc2015/data. We only provide an
example file. Copy all dense trajectory files you want to convert to this
directory.

(2) Run 01_subsample.sh to uniformly sample the converted caches. Adjust the
parameter MAX_SAMPLES to limit the number of feature vectors per sequence.



(B) TRAIN THE BAG-OF-WORDS NETWORK

Go to the directory 01_bow_network_training.

In features/caches, we provide squirrel caches of the 30-dimensional trajectory
descriptor for the weizmann dataset. The files features/test.videos+labels and
features/train.videos+labels define the test/train split and the class labels
for each video.

(1) Run 00_prepareData.sh to create label caches and bundle files for training.
The results can be found in the features directory.

(2) Run 01_normalization.sh to estimate the mean and variance of the training
data. The results are needed to perform a z-score normalization in the neural
network training.

(3) Run 02_train.sh to train the network. In config/training.config you can
find the training parameters which should be well suited for other datasets
as well. In config/network.config you can find the network definition. Note
that you need to adjust the input-dimension for other descriptors (e.g. hog).
Change the number-of-units in the last layer if you have a different number
of classes.

(4) Run 03_extractBoW.sh to extract the learned descriptors from the neural
network. You can find the generated files in the results directory. The
features are stored as squirrel caches and as ascii files for further processing,
e.g. for classification using a (nonlinear) support vector machine. We used
libsvm in the paper.
